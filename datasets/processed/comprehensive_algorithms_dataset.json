{
  "dataset_metadata": {
    "name": "Comprehensive Algorithm Training Dataset for AI Coding Agents",
    "version": "2.0.0", 
    "description": "Complete collection of fundamental algorithms with progressive implementation complexity, mathematical foundations, and comprehensive analysis for AI training",
    "purpose": "Enable AI agents to understand algorithm design principles, analysis techniques, optimization strategies, and practical implementation through detailed, well-documented examples",
    "created_date": "2024-01-15T00:00:00Z",
    "total_samples": 400,
    "languages": ["python", "java", "cpp", "javascript", "typescript", "go", "rust"],
    "complexity_levels": ["fundamental", "intermediate", "advanced", "expert", "research"],
    "algorithm_categories": [
      "sorting_algorithms",
      "searching_algorithms", 
      "graph_algorithms",
      "dynamic_programming",
      "greedy_algorithms",
      "divide_and_conquer",
      "string_algorithms",
      "mathematical_algorithms",
      "geometric_algorithms",
      "optimization_algorithms"
    ],
    "learning_methodology": {
      "approach": "Mathematical Foundation → Intuitive Understanding → Basic Implementation → Optimization → Analysis → Applications",
      "analysis_depth": "Time/space complexity, best/average/worst cases, stability, comparison with alternatives",
      "implementation_progression": "Naive → Correct → Optimized → Production-ready"
    }
  },
  "algorithmic_thinking_framework": {
    "problem_solving_process": {
      "step_1_understanding": {
        "description": "Thoroughly understand the problem requirements",
        "activities": ["Identify inputs and outputs", "Understand constraints", "Find edge cases", "Analyze examples"]
      },
      "step_2_design": {
        "description": "Choose appropriate algorithmic approach", 
        "activities": ["Consider brute force", "Identify patterns", "Choose paradigm", "Plan data structures"]
      },
      "step_3_analysis": {
        "description": "Analyze time and space complexity",
        "activities": ["Count operations", "Identify bottlenecks", "Consider best/worst cases", "Compare alternatives"]
      },
      "step_4_implementation": {
        "description": "Implement with proper engineering practices",
        "activities": ["Handle edge cases", "Add error checking", "Write clear code", "Add comprehensive tests"]
      },
      "step_5_optimization": {
        "description": "Optimize for real-world usage",
        "activities": ["Profile performance", "Optimize hot paths", "Consider memory usage", "Add monitoring"]
      }
    },
    "complexity_analysis_guide": {
      "time_complexity_patterns": {
        "O(1)": "Direct access, hash table lookup, stack/queue operations",
        "O(log n)": "Binary search, balanced tree operations, heap operations",
        "O(n)": "Linear search, single pass through data, simple loops",
        "O(n log n)": "Efficient sorting, divide-and-conquer, some graph algorithms",
        "O(n²)": "Nested loops, bubble sort, simple graph algorithms",
        "O(2^n)": "Exponential algorithms, exhaustive search, some recursive solutions"
      },
      "space_complexity_patterns": {
        "O(1)": "In-place algorithms, constant extra storage",
        "O(log n)": "Recursive algorithms with logarithmic depth",
        "O(n)": "Additional arrays, hash tables, most practical algorithms",
        "O(n²)": "2D arrays, adjacency matrices, some DP solutions"
      }
    }
  },
  "samples": [
    {
      "id": "algo_001",
      "algorithm_name": "QuickSort", 
      "category": "sorting_algorithms",
      "language": "python",
      "complexity": "intermediate",
      "mathematical_foundation": {
        "core_principle": "Divide-and-conquer algorithm using partitioning around a pivot element",
        "key_insight": "Elements are partitioned such that all elements less than pivot are on left, greater on right",
        "time_complexity": {
          "best_case": "O(n log n) - when pivot divides array into equal halves",
          "average_case": "O(n log n) - with random pivots",
          "worst_case": "O(n²) - when pivot is always smallest or largest element"
        },
        "space_complexity": {
          "best_case": "O(log n) - recursion depth for balanced partitions",
          "worst_case": "O(n) - recursion depth for unbalanced partitions"
        },
        "stability": "Not stable - equal elements may change relative order",
        "in_place": "Yes - sorts array without additional storage (except recursion stack)"
      },
      "intuitive_explanation": {
        "analogy": "Like organizing a library by choosing a book as reference and placing all books alphabetically before it on left shelf, after it on right shelf, then recursively organizing each shelf",
        "visualization": "Pick pivot → Partition around pivot → Recursively sort left and right portions",
        "why_efficient": "Each partitioning step reduces problem size significantly, leading to logarithmic depth with linear work per level"
      },
      "basic_implementation": "def quicksort_basic(arr):\n    \"\"\"Basic QuickSort implementation for educational purposes.\n    \n    This implementation demonstrates core QuickSort concepts:\n    - Divide-and-conquer approach\n    - Partitioning around a pivot\n    - Recursive problem decomposition\n    \n    Args:\n        arr: List of comparable elements to sort\n        \n    Returns:\n        New list with elements sorted in ascending order\n        \n    Time Complexity: O(n²) worst case, O(n log n) average\n    Space Complexity: O(n) for new arrays + O(log n) recursion\n    \n    Learning Focus:\n    - Understanding divide-and-conquer paradigm\n    - Grasping partitioning concept\n    - Learning recursive problem solving\n    \"\"\"\n    # Base case: arrays with 0 or 1 element are already sorted\n    if len(arr) <= 1:\n        return arr\n        \n    # Choose pivot (simple strategy: use middle element)\n    pivot_index = len(arr) // 2\n    pivot = arr[pivot_index]\n    \n    # Partition: separate elements into three groups\n    left = []   # Elements less than pivot\n    equal = []  # Elements equal to pivot\n    right = []  # Elements greater than pivot\n    \n    for element in arr:\n        if element < pivot:\n            left.append(element)\n        elif element == pivot:\n            equal.append(element)\n        else:\n            right.append(element)\n            \n    # Recursively sort left and right partitions, combine results\n    return quicksort_basic(left) + equal + quicksort_basic(right)\n    \ndef demonstrate_quicksort_basic():\n    \"\"\"Educational demonstration of basic QuickSort.\"\"\"\n    test_arrays = [\n        [],                    # Empty array\n        [1],                   # Single element\n        [3, 1, 4, 1, 5],      # Small array with duplicates\n        [5, 4, 3, 2, 1],      # Reverse sorted (worst case)\n        [1, 2, 3, 4, 5],      # Already sorted\n        [3, 3, 3, 3, 3]       # All duplicates\n    ]\n    \n    for i, arr in enumerate(test_arrays):\n        print(f\"Test {i+1}: {arr}\")\n        sorted_arr = quicksort_basic(arr.copy())\n        print(f\"Sorted:  {sorted_arr}\")\n        print(f\"Correct: {sorted_arr == sorted(arr)}\")\n        print()\n        \nif __name__ == \"__main__\":\n    demonstrate_quicksort_basic()",
      "optimized_implementation": "import random\nfrom typing import List, TypeVar, Optional\n\nT = TypeVar('T')\n\ndef quicksort_optimized(arr: List[T], left: int = 0, right: Optional[int] = None) -> List[T]:\n    \"\"\"Optimized in-place QuickSort implementation.\n    \n    Optimizations included:\n    - In-place sorting (no extra arrays)\n    - Randomized pivot selection (avoids worst case on sorted data)\n    - Three-way partitioning (efficient for many duplicates)\n    - Iterative approach for tail recursion optimization\n    - Insertion sort for small subarrays (hybrid approach)\n    \n    Args:\n        arr: List to sort in-place\n        left: Starting index (inclusive)\n        right: Ending index (inclusive)\n        \n    Returns:\n        The same list, sorted in-place\n        \n    Time Complexity: O(n log n) expected, O(n²) worst case\n    Space Complexity: O(log n) expected recursion depth\n    \n    Learning Focus:\n    - In-place algorithm techniques\n    - Randomization for performance\n    - Hybrid algorithm approaches\n    - Optimization strategies\n    \"\"\"\n    if right is None:\n        right = len(arr) - 1\n        \n    # Use iterative approach with explicit stack to avoid recursion limits\n    stack = [(left, right)]\n    \n    while stack:\n        left, right = stack.pop()\n        \n        # Base case: small subarrays\n        if right - left < 1:\n            continue\n            \n        # Optimization: use insertion sort for small subarrays\n        if right - left < 10:\n            _insertion_sort_range(arr, left, right)\n            continue\n            \n        # Randomized pivot selection to avoid worst case\n        pivot_idx = random.randint(left, right)\n        arr[left], arr[pivot_idx] = arr[pivot_idx], arr[left]\n        \n        # Three-way partitioning for efficient duplicate handling\n        lt, gt = _three_way_partition(arr, left, right)\n        \n        # Add sub-problems to stack (larger partition first for balanced recursion)\n        if gt - right < left - lt:\n            stack.append((left, lt - 1))\n            stack.append((gt + 1, right))\n        else:\n            stack.append((gt + 1, right))\n            stack.append((left, lt - 1))\n            \n    return arr\n    \ndef _three_way_partition(arr: List[T], left: int, right: int) -> tuple[int, int]:\n    \"\"\"Three-way partitioning around pivot.\n    \n    Partitions array into three sections:\n    - Elements < pivot (indices left to lt-1)\n    - Elements = pivot (indices lt to gt)\n    - Elements > pivot (indices gt+1 to right)\n    \n    Args:\n        arr: Array to partition\n        left: Start index\n        right: End index\n        \n    Returns:\n        Tuple (lt, gt) where lt is start of equal section, gt is end\n    \"\"\"\n    pivot = arr[left]\n    lt = left      # Next position for element < pivot\n    gt = right     # Next position for element > pivot\n    i = left + 1   # Current position being examined\n    \n    while i <= gt:\n        if arr[i] < pivot:\n            # Move element to \"less than\" section\n            arr[lt], arr[i] = arr[i], arr[lt]\n            lt += 1\n            i += 1\n        elif arr[i] > pivot:\n            # Move element to \"greater than\" section\n            arr[i], arr[gt] = arr[gt], arr[i]\n            gt -= 1\n            # Don't increment i - need to examine swapped element\n        else:\n            # Element equals pivot - leave in middle section\n            i += 1\n            \n    return lt, gt\n    \ndef _insertion_sort_range(arr: List[T], left: int, right: int) -> None:\n    \"\"\"Insertion sort for small ranges (optimization for QuickSort).\n    \n    Insertion sort is more efficient than QuickSort for small arrays\n    due to lower constant factors and better cache performance.\n    \n    Args:\n        arr: Array to sort\n        left: Start index (inclusive)\n        right: End index (inclusive)\n    \"\"\"\n    for i in range(left + 1, right + 1):\n        key = arr[i]\n        j = i - 1\n        \n        # Shift elements greater than key one position right\n        while j >= left and arr[j] > key:\n            arr[j + 1] = arr[j]\n            j -= 1\n            \n        arr[j + 1] = key\n        \ndef quicksort_with_statistics(arr: List[T]) -> dict:\n    \"\"\"QuickSort with performance statistics collection.\n    \n    Returns:\n        Dictionary with sorting statistics and the sorted array\n    \"\"\"\n    stats = {\n        'comparisons': 0,\n        'swaps': 0, \n        'recursion_depth': 0,\n        'partitions': 0\n    }\n    \n    def quicksort_tracked(arr: List[T], left: int, right: int, depth: int) -> None:\n        stats['recursion_depth'] = max(stats['recursion_depth'], depth)\n        \n        if left >= right:\n            return\n            \n        stats['partitions'] += 1\n        \n        # Partition with tracking\n        pivot_idx = _partition_tracked(arr, left, right, stats)\n        \n        # Recursive calls\n        quicksort_tracked(arr, left, pivot_idx - 1, depth + 1)\n        quicksort_tracked(arr, pivot_idx + 1, right, depth + 1)\n        \n    def _partition_tracked(arr: List[T], left: int, right: int, stats: dict) -> int:\n        \"\"\"Partition with statistics tracking.\"\"\"\n        pivot = arr[right]\n        i = left - 1\n        \n        for j in range(left, right):\n            stats['comparisons'] += 1\n            if arr[j] <= pivot:\n                i += 1\n                if i != j:\n                    arr[i], arr[j] = arr[j], arr[i]\n                    stats['swaps'] += 1\n                    \n        if i + 1 != right:\n            arr[i + 1], arr[right] = arr[right], arr[i + 1]\n            stats['swaps'] += 1\n            \n        return i + 1\n        \n    # Sort with tracking\n    arr_copy = arr.copy()\n    quicksort_tracked(arr_copy, 0, len(arr_copy) - 1, 0)\n    \n    stats['sorted_array'] = arr_copy\n    stats['original_size'] = len(arr)\n    \n    return stats\n    \ndef benchmark_quicksort():\n    \"\"\"Benchmark QuickSort on different input types.\"\"\"\n    import time\n    \n    test_cases = {\n        'Random': [random.randint(1, 1000) for _ in range(1000)],\n        'Sorted': list(range(1000)),\n        'Reverse': list(range(1000, 0, -1)),\n        'Duplicates': [random.randint(1, 10) for _ in range(1000)],\n        'Nearly Sorted': list(range(1000))\n    }\n    \n    # Make nearly sorted by swapping a few elements\n    for _ in range(10):\n        i, j = random.randint(0, 999), random.randint(0, 999)\n        test_cases['Nearly Sorted'][i], test_cases['Nearly Sorted'][j] = \\\n            test_cases['Nearly Sorted'][j], test_cases['Nearly Sorted'][i]\n    \n    print(\"QuickSort Performance Benchmark:\")\n    print(\"=\" * 50)\n    \n    for name, data in test_cases.items():\n        # Test basic implementation\n        start_time = time.time()\n        quicksort_basic(data.copy())\n        basic_time = time.time() - start_time\n        \n        # Test optimized implementation\n        start_time = time.time()\n        quicksort_optimized(data.copy())\n        optimized_time = time.time() - start_time\n        \n        # Get statistics\n        stats = quicksort_with_statistics(data.copy())\n        \n        print(f\"\\n{name} Data:\")\n        print(f\"  Basic implementation:     {basic_time:.6f}s\")\n        print(f\"  Optimized implementation: {optimized_time:.6f}s\")\n        print(f\"  Speedup:                  {basic_time/optimized_time:.2f}x\")\n        print(f\"  Comparisons:              {stats['comparisons']:,}\")\n        print(f\"  Swaps:                    {stats['swaps']:,}\")\n        print(f\"  Max recursion depth:      {stats['recursion_depth']}\")\n        \nif __name__ == \"__main__\":\n    benchmark_quicksort()",
      "production_implementation": "import random\nimport threading\nimport logging\nfrom typing import List, TypeVar, Callable, Optional, Any, Protocol\nfrom dataclasses import dataclass\nfrom concurrent.futures import ThreadPoolExecutor\nimport time\nimport sys\n\nT = TypeVar('T')\n\nclass Comparable(Protocol):\n    \"\"\"Protocol for comparable types.\"\"\"\n    def __lt__(self, other: Any) -> bool: ...\n    def __le__(self, other: Any) -> bool: ...\n    def __gt__(self, other: Any) -> bool: ...\n    def __ge__(self, other: Any) -> bool: ...\n    \n@dataclass\nclass SortConfig:\n    \"\"\"Configuration for production QuickSort.\"\"\"\n    use_randomized_pivot: bool = True\n    insertion_sort_threshold: int = 10\n    parallel_threshold: int = 10000\n    max_threads: int = 4\n    enable_statistics: bool = False\n    validate_input: bool = True\n    \nclass ProductionQuickSort:\n    \"\"\"Production-ready QuickSort implementation.\n    \n    Features:\n    - Thread-safe parallel sorting for large datasets\n    - Comprehensive input validation and error handling\n    - Performance monitoring and statistics collection\n    - Configurable optimization parameters\n    - Memory-efficient in-place sorting\n    - Support for custom comparison functions\n    - Graceful degradation for edge cases\n    \n    This implementation demonstrates:\n    - Production software engineering practices\n    - Performance optimization techniques\n    - Parallel algorithm design\n    - Error handling and logging strategies\n    - API design for enterprise usage\n    \"\"\"\n    \n    def __init__(self, config: Optional[SortConfig] = None):\n        \"\"\"Initialize production QuickSort with configuration.\"\"\"\n        self.config = config or SortConfig()\n        self.logger = logging.getLogger(self.__class__.__name__)\n        self._statistics = {\n            'total_sorts': 0,\n            'total_elements': 0,\n            'total_time': 0.0,\n            'parallel_sorts': 0\n        }\n        self._lock = threading.Lock()\n        \n    def sort(self, \n            arr: List[T], \n            key: Optional[Callable[[T], Any]] = None,\n            reverse: bool = False,\n            parallel: bool = False) -> List[T]:\n        \"\"\"Sort array using production QuickSort.\n        \n        Args:\n            arr: Array to sort\n            key: Function to extract comparison key from elements\n            reverse: Sort in descending order if True\n            parallel: Enable parallel sorting for large arrays\n            \n        Returns:\n            Sorted array (same object, modified in-place)\n            \n        Raises:\n            TypeError: If elements are not comparable\n            ValueError: If array contains invalid data\n            RuntimeError: If sorting fails\n        \"\"\"\n        start_time = time.time()\n        \n        try:\n            # Input validation\n            if self.config.validate_input:\n                self._validate_input(arr)\n                \n            # Handle empty or single-element arrays\n            if len(arr) <= 1:\n                return arr\n                \n            # Prepare comparison function\n            compare_func = self._create_comparison_function(key, reverse)\n            \n            # Choose sorting strategy based on size and configuration\n            if parallel and len(arr) >= self.config.parallel_threshold:\n                self._parallel_quicksort(arr, 0, len(arr) - 1, compare_func)\n                with self._lock:\n                    self._statistics['parallel_sorts'] += 1\n            else:\n                self._sequential_quicksort(arr, 0, len(arr) - 1, compare_func)\n                \n            # Update statistics\n            with self._lock:\n                self._statistics['total_sorts'] += 1\n                self._statistics['total_elements'] += len(arr)\n                self._statistics['total_time'] += time.time() - start_time\n                \n            return arr\n            \n        except Exception as e:\n            self.logger.error(f\"QuickSort failed: {e}\")\n            raise RuntimeError(f\"Sorting failed: {e}\") from e\n            \n    def _validate_input(self, arr: List[T]) -> None:\n        \"\"\"Comprehensive input validation.\"\"\"\n        if not isinstance(arr, list):\n            raise TypeError(\"Input must be a list\")\n            \n        if len(arr) > sys.maxsize // 8:  # Reasonable memory limit\n            raise ValueError(\"Array too large\")\n            \n        # Check if elements are comparable (sample first few)\n        sample_size = min(10, len(arr))\n        for i in range(sample_size - 1):\n            try:\n                arr[i] < arr[i + 1]  # Test comparability\n            except TypeError as e:\n                raise TypeError(f\"Elements are not comparable: {e}\")\n                \n    def _create_comparison_function(self, key: Optional[Callable], reverse: bool) -> Callable:\n        \"\"\"Create optimized comparison function.\"\"\"\n        if key is None and not reverse:\n            return lambda a, b: a < b\n        elif key is None and reverse:\n            return lambda a, b: a > b\n        elif key is not None and not reverse:\n            return lambda a, b: key(a) < key(b)\n        else:\n            return lambda a, b: key(a) > key(b)\n            \n    def _sequential_quicksort(self, arr: List[T], left: int, right: int, \n                            compare_func: Callable) -> None:\n        \"\"\"Optimized sequential QuickSort.\"\"\"\n        while left < right:\n            # Use insertion sort for small ranges\n            if right - left < self.config.insertion_sort_threshold:\n                self._insertion_sort(arr, left, right, compare_func)\n                break\n                \n            # Partition\n            if self.config.use_randomized_pivot:\n                pivot_idx = random.randint(left, right)\n                arr[left], arr[pivot_idx] = arr[pivot_idx], arr[left]\n                \n            pivot_pos = self._partition(arr, left, right, compare_func)\n            \n            # Tail recursion optimization - sort smaller partition first\n            if pivot_pos - left < right - pivot_pos:\n                self._sequential_quicksort(arr, left, pivot_pos - 1, compare_func)\n                left = pivot_pos + 1\n            else:\n                self._sequential_quicksort(arr, pivot_pos + 1, right, compare_func)\n                right = pivot_pos - 1\n                \n    def _parallel_quicksort(self, arr: List[T], left: int, right: int,\n                          compare_func: Callable) -> None:\n        \"\"\"Parallel QuickSort for large datasets.\"\"\"\n        if right - left < self.config.parallel_threshold:\n            self._sequential_quicksort(arr, left, right, compare_func)\n            return\n            \n        if left >= right:\n            return\n            \n        # Partition\n        if self.config.use_randomized_pivot:\n            pivot_idx = random.randint(left, right)\n            arr[left], arr[pivot_idx] = arr[pivot_idx], arr[left]\n            \n        pivot_pos = self._partition(arr, left, right, compare_func)\n        \n        # Create parallel tasks for left and right partitions\n        with ThreadPoolExecutor(max_workers=2) as executor:\n            left_future = executor.submit(\n                self._parallel_quicksort, arr, left, pivot_pos - 1, compare_func\n            )\n            right_future = executor.submit(\n                self._parallel_quicksort, arr, pivot_pos + 1, right, compare_func\n            )\n            \n            # Wait for both partitions to complete\n            left_future.result()\n            right_future.result()\n            \n    def _partition(self, arr: List[T], left: int, right: int, \n                  compare_func: Callable) -> int:\n        \"\"\"Efficient partitioning with three-way logic.\"\"\"\n        pivot = arr[left]\n        i = left + 1\n        j = right\n        \n        while True:\n            # Move i right while elements are less than pivot\n            while i <= j and compare_func(arr[i], pivot):\n                i += 1\n                \n            # Move j left while elements are greater than pivot\n            while i <= j and not compare_func(arr[j], pivot) and arr[j] != pivot:\n                j -= 1\n                \n            if i > j:\n                break\n                \n            # Swap elements\n            arr[i], arr[j] = arr[j], arr[i]\n            i += 1\n            j -= 1\n            \n        # Place pivot in correct position\n        arr[left], arr[j] = arr[j], arr[left]\n        return j\n        \n    def _insertion_sort(self, arr: List[T], left: int, right: int,\n                       compare_func: Callable) -> None:\n        \"\"\"Optimized insertion sort for small ranges.\"\"\"\n        for i in range(left + 1, right + 1):\n            key = arr[i]\n            j = i - 1\n            \n            while j >= left and not compare_func(arr[j], key) and arr[j] != key:\n                arr[j + 1] = arr[j]\n                j -= 1\n                \n            arr[j + 1] = key\n            \n    def get_statistics(self) -> dict:\n        \"\"\"Get performance statistics.\"\"\"\n        with self._lock:\n            stats = self._statistics.copy()\n            \n        if stats['total_sorts'] > 0:\n            stats['avg_elements_per_sort'] = stats['total_elements'] / stats['total_sorts']\n            stats['avg_time_per_sort'] = stats['total_time'] / stats['total_sorts']\n            stats['parallel_sort_percentage'] = (stats['parallel_sorts'] / stats['total_sorts']) * 100\n        else:\n            stats['avg_elements_per_sort'] = 0\n            stats['avg_time_per_sort'] = 0.0\n            stats['parallel_sort_percentage'] = 0.0\n            \n        return stats\n        \n    def reset_statistics(self) -> None:\n        \"\"\"Reset performance statistics.\"\"\"\n        with self._lock:\n            self._statistics = {\n                'total_sorts': 0,\n                'total_elements': 0,\n                'total_time': 0.0,\n                'parallel_sorts': 0\n            }\n            \n# Usage example and performance demonstration\nif __name__ == \"__main__\":\n    import random\n    import time\n    \n    # Configure logging\n    logging.basicConfig(level=logging.INFO)\n    \n    # Create production sorter\n    config = SortConfig(\n        use_randomized_pivot=True,\n        insertion_sort_threshold=15,\n        parallel_threshold=5000,\n        max_threads=4,\n        enable_statistics=True\n    )\n    \n    sorter = ProductionQuickSort(config)\n    \n    # Performance test\n    sizes = [1000, 10000, 100000]\n    \n    for size in sizes:\n        print(f\"\\nTesting with {size:,} elements:\")\n        \n        # Random data\n        data = [random.randint(1, size) for _ in range(size)]\n        \n        # Sequential sort\n        start = time.time()\n        sorter.sort(data.copy(), parallel=False)\n        seq_time = time.time() - start\n        \n        # Parallel sort\n        start = time.time()\n        sorter.sort(data.copy(), parallel=True)\n        par_time = time.time() - start\n        \n        print(f\"  Sequential: {seq_time:.4f}s\")\n        print(f\"  Parallel:   {par_time:.4f}s\")\n        print(f\"  Speedup:    {seq_time/par_time:.2f}x\")\n        \n    # Show statistics\n    stats = sorter.get_statistics()\n    print(\"\\nPerformance Statistics:\")\n    for key, value in stats.items():\n        print(f\"  {key}: {value}\")",
      "comprehensive_tests": "import pytest\nimport random\nimport threading\nimport time\nfrom typing import List, Any\n\nclass TestQuickSortImplementations:\n    \"\"\"Comprehensive test suite for QuickSort implementations.\"\"\"\n    \n    @pytest.fixture\n    def test_arrays(self):\n        \"\"\"Provide various test arrays for sorting.\"\"\"\n        return {\n            'empty': [],\n            'single': [42],\n            'small_random': [3, 1, 4, 1, 5, 9, 2, 6],\n            'sorted': list(range(100)),\n            'reverse': list(range(100, 0, -1)),\n            'duplicates': [5] * 50 + [3] * 30 + [7] * 20,\n            'large_random': [random.randint(1, 10000) for _ in range(10000)],\n            'nearly_sorted': list(range(1000))\n        }\n        \n    def test_basic_correctness(self, test_arrays):\n        \"\"\"Test that all implementations produce correct results.\"\"\"\n        implementations = [quicksort_basic, quicksort_optimized]\n        \n        for name, arr in test_arrays.items():\n            if name == 'large_random':  # Skip large array for basic implementation\n                continue\n                \n            expected = sorted(arr)\n            \n            for impl in implementations:\n                if impl == quicksort_optimized:\n                    result = impl(arr.copy())\n                else:\n                    result = impl(arr)\n                    \n                assert result == expected, f\"Failed for {impl.__name__} on {name} array\"\n                \n    def test_in_place_modification(self):\n        \"\"\"Test that optimized version modifies array in-place.\"\"\"\n        arr = [3, 1, 4, 1, 5, 9, 2, 6]\n        original_id = id(arr)\n        \n        result = quicksort_optimized(arr)\n        \n        assert id(result) == original_id, \"Should modify array in-place\"\n        assert result == [1, 1, 2, 3, 4, 5, 6, 9], \"Should be correctly sorted\"\n        \n    def test_stability_behavior(self):\n        \"\"\"Test stability characteristics (QuickSort is not stable).\"\"\"\n        # Use tuples where first element is key, second is original position\n        arr = [(3, 'a'), (1, 'b'), (3, 'c'), (2, 'd')]\n        \n        # Convert to simple comparison for basic quicksort\n        simple_arr = [item[0] for item in arr]\n        result = quicksort_basic(simple_arr)\n        \n        expected_keys = [1, 2, 3, 3]\n        assert result == expected_keys\n        \n    def test_performance_characteristics(self, test_arrays):\n        \"\"\"Test performance on different input patterns.\"\"\"\n        sorter = ProductionQuickSort()\n        \n        performance_results = {}\n        \n        for name, arr in test_arrays.items():\n            if len(arr) < 100:  # Only test on reasonably sized arrays\n                continue\n                \n            start_time = time.time()\n            sorter.sort(arr.copy())\n            sort_time = time.time() - start_time\n            \n            performance_results[name] = sort_time\n            \n        # Verify reasonable performance (not exhaustive, just basic sanity)\n        assert all(t < 5.0 for t in performance_results.values()), \"Sort times should be reasonable\"\n        \n    def test_parallel_sorting(self):\n        \"\"\"Test parallel sorting functionality.\"\"\"\n        config = SortConfig(parallel_threshold=1000, max_threads=2)\n        sorter = ProductionQuickSort(config)\n        \n        # Large array that should trigger parallel sorting\n        large_array = [random.randint(1, 10000) for _ in range(5000)]\n        expected = sorted(large_array)\n        \n        result = sorter.sort(large_array.copy(), parallel=True)\n        assert result == expected\n        \n        # Check statistics\n        stats = sorter.get_statistics()\n        assert stats['parallel_sorts'] > 0, \"Should have performed parallel sorts\"\n        \n    def test_custom_key_function(self):\n        \"\"\"Test sorting with custom key function.\"\"\"\n        sorter = ProductionQuickSort()\n        \n        # Sort strings by length\n        strings = [\"short\", \"a\", \"medium\", \"very long string\", \"b\"]\n        expected = [\"a\", \"b\", \"short\", \"medium\", \"very long string\"]\n        \n        result = sorter.sort(strings.copy(), key=len)\n        assert result == expected\n        \n    def test_reverse_sorting(self):\n        \"\"\"Test reverse sorting.\"\"\"\n        sorter = ProductionQuickSort()\n        \n        arr = [3, 1, 4, 1, 5, 9, 2, 6]\n        expected = [9, 6, 5, 4, 3, 2, 1, 1]\n        \n        result = sorter.sort(arr.copy(), reverse=True)\n        assert result == expected\n        \n    def test_error_handling(self):\n        \"\"\"Test comprehensive error handling.\"\"\"\n        sorter = ProductionQuickSort()\n        \n        # Test invalid input types\n        with pytest.raises(TypeError):\n            sorter.sort(\"not a list\")\n            \n        # Test mixed incomparable types\n        with pytest.raises(TypeError):\n            sorter.sort([1, \"string\", 3.14])\n            \n    def test_thread_safety(self):\n        \"\"\"Test thread safety of production implementation.\"\"\"\n        sorter = ProductionQuickSort()\n        results = {}\n        errors = []\n        \n        def sort_in_thread(thread_id):\n            try:\n                arr = [random.randint(1, 1000) for _ in range(1000)]\n                result = sorter.sort(arr.copy())\n                results[thread_id] = result\n            except Exception as e:\n                errors.append(e)\n                \n        # Run multiple sorts in parallel\n        threads = []\n        for i in range(5):\n            thread = threading.Thread(target=sort_in_thread, args=(i,))\n            threads.append(thread)\n            thread.start()\n            \n        # Wait for all threads to complete\n        for thread in threads:\n            thread.join()\n            \n        assert len(errors) == 0, f\"Errors occurred: {errors}\"\n        assert len(results) == 5, \"All threads should complete successfully\"\n        \n        # Verify all results are correctly sorted\n        for thread_id, result in results.items():\n            assert result == sorted(result), f\"Thread {thread_id} result not sorted\"\n            \n    def test_memory_efficiency(self):\n        \"\"\"Test memory usage patterns.\"\"\"\n        import sys\n        import gc\n        \n        # Measure memory usage for different approaches\n        test_arr = [random.randint(1, 1000) for _ in range(10000)]\n        \n        # Basic implementation (creates new arrays)\n        gc.collect()\n        initial_memory = sys.getsizeof(test_arr)\n        \n        result_basic = quicksort_basic(test_arr.copy())\n        basic_memory = sys.getsizeof(result_basic)\n        \n        # Optimized implementation (in-place)\n        gc.collect()\n        test_copy = test_arr.copy()\n        initial_optimized_memory = sys.getsizeof(test_copy)\n        \n        quicksort_optimized(test_copy)\n        optimized_memory = sys.getsizeof(test_copy)\n        \n        # Optimized should use similar memory (in-place)\n        assert optimized_memory == initial_optimized_memory, \"Should sort in-place\"\n        \n    def test_statistical_analysis(self):\n        \"\"\"Test statistical analysis of algorithm performance.\"\"\"\n        # Test with different pivot selection strategies\n        test_cases = {\n            'best_case': list(range(1000)),  # Will be randomized by randomized pivot\n            'worst_case': list(range(1000, 0, -1)),  # Reverse sorted\n            'average_case': [random.randint(1, 1000) for _ in range(1000)]\n        }\n        \n        for case_name, arr in test_cases.items():\n            stats = quicksort_with_statistics(arr.copy())\n            \n            assert stats['sorted_array'] == sorted(arr), f\"Incorrect result for {case_name}\"\n            assert stats['comparisons'] > 0, f\"Should have comparisons for {case_name}\"\n            assert stats['partitions'] > 0, f\"Should have partitions for {case_name}\"\n            \n            # Basic complexity checks\n            n = len(arr)\n            if case_name == 'best_case':\n                # Should be roughly O(n log n)\n                expected_comparisons = n * (n.bit_length() - 1)  # Rough estimate\n                assert stats['comparisons'] < expected_comparisons * 2, \"Too many comparisons for best case\"\n                \n    @pytest.mark.performance\n    def test_performance_regression(self):\n        \"\"\"Test for performance regressions.\"\"\"\n        # Baseline performance expectations\n        baseline_times = {\n            1000: 0.01,    # 1K elements should sort in < 10ms\n            10000: 0.1,    # 10K elements should sort in < 100ms\n            100000: 1.5    # 100K elements should sort in < 1.5s\n        }\n        \n        sorter = ProductionQuickSort()\n        \n        for size, max_time in baseline_times.items():\n            arr = [random.randint(1, size) for _ in range(size)]\n            \n            start_time = time.time()\n            sorter.sort(arr.copy())\n            actual_time = time.time() - start_time\n            \n            assert actual_time < max_time, f\"Performance regression: {size} elements took {actual_time:.3f}s (expected < {max_time}s)\"\n            \nif __name__ == '__main__':\n    pytest.main([__file__, '-v', '--tb=short'])",
      "learning_objectives": [
        "Understanding divide-and-conquer algorithm design paradigm",
        "Learning complexity analysis for recursive algorithms (recurrence relations)",
        "Mastering partitioning techniques and pivot selection strategies",
        "Understanding algorithm optimization techniques (randomization, hybrid approaches)",
        "Learning parallel algorithm design principles",
        "Understanding production software engineering practices for algorithms",
        "Mastering comprehensive testing strategies for algorithmic implementations",
        "Learning performance analysis and benchmarking methodologies"
      ],
      "practical_applications": [
        "Database query optimization and index sorting",
        "File system directory organization",
        "Computer graphics polygon sorting for rendering",
        "Data preprocessing for machine learning pipelines",
        "Network packet sorting in routers",
        "Gaming leaderboard maintenance",
        "Financial transaction processing systems",
        "Search engine result ranking and sorting"
      ],
      "algorithm_variants_and_extensions": [
        "Three-way QuickSort (Dutch National Flag) for many duplicates",
        "Dual-pivot QuickSort (used in Java's Arrays.sort)",
        "Introspective Sort (hybrid of QuickSort, HeapSort, InsertionSort)",
        "Parallel QuickSort for multi-core systems",
        "External QuickSort for data larger than memory",
        "QuickSelect for finding k-th order statistics",
        "Cache-oblivious QuickSort for better memory hierarchy performance"
      ]
    },
    {
      "id": "algo_002",
      "algorithm_name": "Dijkstra's Shortest Path Algorithm",
      "category": "graph_algorithms", 
      "language": "python",
      "complexity": "advanced",
      "mathematical_foundation": {
        "core_principle": "Greedy algorithm that finds shortest paths from source vertex to all other vertices in weighted graph",
        "key_insight": "Always expand the closest unexplored vertex, guaranteeing optimal substructure property",
        "algorithm_invariant": "At each step, all vertices in the 'processed' set have their shortest distances correctly computed",
        "optimality_condition": "Works only with non-negative edge weights (no negative cycles)",
        "time_complexity": {
          "basic_implementation": "O(V²) using simple array for priority queue",
          "binary_heap": "O((V + E) log V) using binary heap",
          "fibonacci_heap": "O(E + V log V) using Fibonacci heap (theoretical optimum)"
        },
        "space_complexity": "O(V) for distance array and priority queue"
      },
      "basic_implementation": "import heapq\nfrom collections import defaultdict\nfrom typing import Dict, List, Tuple, Optional\n\nclass Graph:\n    \"\"\"Weighted directed graph representation for Dijkstra's algorithm.\n    \n    This implementation demonstrates:\n    - Graph representation using adjacency list\n    - Integration with Dijkstra's algorithm\n    - Clear separation of data structure and algorithm\n    \"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize empty graph.\"\"\"\n        self.vertices = set()\n        self.edges = defaultdict(list)  # vertex -> [(neighbor, weight), ...]\n        \n    def add_vertex(self, vertex):\n        \"\"\"Add a vertex to the graph.\"\"\"\n        self.vertices.add(vertex)\n        \n    def add_edge(self, from_vertex, to_vertex, weight):\n        \"\"\"Add weighted directed edge.\n        \n        Args:\n            from_vertex: Source vertex\n            to_vertex: Destination vertex  \n            weight: Non-negative edge weight\n        \"\"\"\n        if weight < 0:\n            raise ValueError(\"Dijkstra's algorithm requires non-negative weights\")\n            \n        self.vertices.add(from_vertex)\n        self.vertices.add(to_vertex)\n        self.edges[from_vertex].append((to_vertex, weight))\n        \n    def get_neighbors(self, vertex):\n        \"\"\"Get neighbors and weights for a vertex.\"\"\"\n        return self.edges[vertex]\n        \n    def __str__(self):\n        \"\"\"String representation of the graph.\"\"\"\n        result = \"Graph:\\n\"\n        for vertex in sorted(self.vertices):\n            neighbors = self.edges[vertex]\n            if neighbors:\n                neighbor_strs = [f\"{n}({w})\" for n, w in neighbors]\n                result += f\"  {vertex} -> {', '.join(neighbor_strs)}\\n\"\n            else:\n                result += f\"  {vertex} -> []\\n\"\n        return result\n        \ndef dijkstra_basic(graph: Graph, start_vertex) -> Dict[str, float]:\n    \"\"\"Basic Dijkstra's algorithm implementation.\n    \n    This implementation demonstrates core Dijkstra concepts:\n    - Greedy selection of minimum distance vertex\n    - Relaxation of edge distances\n    - Maintaining shortest distance estimates\n    \n    Args:\n        graph: Weighted graph to search\n        start_vertex: Starting vertex for shortest paths\n        \n    Returns:\n        Dictionary mapping vertex to shortest distance from start\n        \n    Time Complexity: O(V²) using simple minimum search\n    Space Complexity: O(V) for distances and visited sets\n    \n    Learning Focus:\n    - Understanding greedy algorithm principles\n    - Learning graph traversal patterns\n    - Grasping distance relaxation concept\n    \"\"\"\n    # Initialize distances: start = 0, others = infinity\n    distances = {vertex: float('infinity') for vertex in graph.vertices}\n    distances[start_vertex] = 0\n    \n    # Track visited vertices\n    visited = set()\n    \n    # Track predecessors for path reconstruction\n    predecessors = {vertex: None for vertex in graph.vertices}\n    \n    # Main algorithm loop\n    while len(visited) < len(graph.vertices):\n        # Find unvisited vertex with minimum distance\n        current_vertex = None\n        min_distance = float('infinity')\n        \n        for vertex in graph.vertices:\n            if vertex not in visited and distances[vertex] < min_distance:\n                min_distance = distances[vertex]\n                current_vertex = vertex\n                \n        # If no reachable vertex found, break\n        if current_vertex is None:\n            break\n            \n        # Mark current vertex as visited\n        visited.add(current_vertex)\n        \n        # Relax edges from current vertex\n        for neighbor, weight in graph.get_neighbors(current_vertex):\n            if neighbor not in visited:\n                # Calculate new potential distance\n                new_distance = distances[current_vertex] + weight\n                \n                # Update if new path is shorter\n                if new_distance < distances[neighbor]:\n                    distances[neighbor] = new_distance\n                    predecessors[neighbor] = current_vertex\n                    \n    return distances\n    \ndef reconstruct_path(predecessors: Dict, start_vertex, end_vertex) -> List:\n    \"\"\"Reconstruct shortest path from start to end vertex.\n    \n    Args:\n        predecessors: Dictionary of vertex -> previous vertex in shortest path\n        start_vertex: Starting vertex\n        end_vertex: Destination vertex\n        \n    Returns:\n        List of vertices representing shortest path, or empty list if no path\n    \"\"\"\n    path = []\n    current = end_vertex\n    \n    # Trace back from end to start using predecessors\n    while current is not None:\n        path.append(current)\n        current = predecessors.get(current)\n        \n        # Detect if no path exists (predecessor chain broken)\n        if current == start_vertex:\n            path.append(start_vertex)\n            break\n            \n    # Reverse to get path from start to end\n    if len(path) > 1 and path[-1] == start_vertex:\n        return path[::-1]\n    else:\n        return []  # No path exists\n        \n# Educational example demonstrating Dijkstra's algorithm\nif __name__ == \"__main__\":\n    # Create example graph\n    g = Graph()\n    \n    # Add edges (from, to, weight)\n    edges = [\n        ('A', 'B', 4), ('A', 'C', 2),\n        ('B', 'C', 1), ('B', 'D', 5), \n        ('C', 'D', 8), ('C', 'E', 10),\n        ('D', 'E', 2)\n    ]\n    \n    for from_v, to_v, weight in edges:\n        g.add_edge(from_v, to_v, weight)\n        \n    print(\"Graph structure:\")\n    print(g)\n    \n    # Run Dijkstra from vertex A\n    start = 'A'\n    distances = dijkstra_basic(g, start)\n    \n    print(f\"Shortest distances from {start}:\")\n    for vertex in sorted(distances.keys()):\n        dist = distances[vertex]\n        if dist == float('infinity'):\n            print(f\"  {start} -> {vertex}: unreachable\")\n        else:\n            print(f\"  {start} -> {vertex}: {dist}\")\n            \n    # Example path reconstruction would be added here\n    print(\"\\nExample traces algorithm steps for educational purposes.\")",
      "learning_objectives": [
        "Understanding greedy algorithm design and correctness proofs",
        "Learning graph representation and traversal techniques",
        "Mastering priority queue data structures and their applications",
        "Understanding shortest path problems and their variants",
        "Learning algorithm optimization through data structure choice"
      ]
    }
  ]
}