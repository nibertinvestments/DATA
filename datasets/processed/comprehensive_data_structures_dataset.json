{
  "dataset_metadata": {
    "name": "Comprehensive Data Structures Training Dataset for AI Coding Agents",
    "version": "2.0.0",
    "description": "Complete collection of data structures implementations with progressive complexity, comprehensive documentation, and industry-standard best practices for AI training",
    "purpose": "Enable AI agents to understand data structure design patterns, implementation strategies, performance characteristics, and practical applications through detailed, well-documented examples",
    "created_date": "2024-01-15T00:00:00Z",
    "total_samples": 300,
    "languages": ["python", "java", "cpp", "javascript", "typescript", "go", "rust", "csharp"],
    "complexity_levels": ["foundational", "intermediate", "advanced", "expert", "research"],
    "data_structure_categories": [
      "arrays_and_strings",
      "linked_lists",
      "stacks_and_queues", 
      "trees_and_graphs",
      "hash_tables",
      "heaps_and_priority_queues",
      "advanced_trees",
      "specialized_structures",
      "concurrent_structures",
      "cache_friendly_structures"
    ],
    "learning_methodology": {
      "approach": "Conceptual Understanding → Basic Implementation → Optimizations → Production Code → Testing Strategies",
      "documentation_style": "Comprehensive inline documentation with complexity analysis and use case examples",
      "testing_approach": "Unit tests, performance benchmarks, edge case validation, invariant checking"
    }
  },
  "learning_framework": {
    "progressive_complexity": {
      "level_1_foundational": {
        "focus": "Core concepts and basic implementations",
        "characteristics": ["Simple, readable code", "Basic operations", "Clear algorithms", "Educational comments"],
        "goals": ["Understand fundamental principles", "Learn basic operations", "Grasp time/space complexity"]
      },
      "level_2_intermediate": {
        "focus": "Enhanced implementations with error handling",
        "characteristics": ["Input validation", "Exception handling", "More efficient algorithms", "Documentation"],
        "goals": ["Handle edge cases", "Improve robustness", "Optimize common operations"]
      },
      "level_3_advanced": {
        "focus": "Optimized implementations with advanced features",
        "characteristics": ["Performance optimizations", "Advanced algorithms", "Memory management", "Benchmarking"],
        "goals": ["Maximize performance", "Handle large datasets", "Implement advanced variants"]
      },
      "level_4_expert": {
        "focus": "Production-ready implementations",
        "characteristics": ["Thread safety", "Comprehensive testing", "API design", "Maintenance considerations"],
        "goals": ["Production deployment", "Team collaboration", "Long-term maintenance"]
      },
      "level_5_research": {
        "focus": "Cutting-edge implementations and novel approaches",
        "characteristics": ["Experimental features", "Novel algorithms", "Research techniques", "Theoretical analysis"],
        "goals": ["Explore new approaches", "Advance state-of-art", "Research applications"]
      }
    }
  },
  "samples": [
    {
      "id": "ds_001",
      "data_structure": "Dynamic Array (Vector)",
      "category": "arrays_and_strings",
      "language": "python",
      "complexity": "foundational",
      "conceptual_foundation": {
        "core_concept": "Resizable array that automatically grows when capacity is exceeded",
        "key_operations": ["access", "append", "insert", "delete", "resize"],
        "time_complexity": {
          "access": "O(1)",
          "append_amortized": "O(1)", 
          "append_worst": "O(n)",
          "insert": "O(n)",
          "delete": "O(n)"
        },
        "space_complexity": "O(n)",
        "use_cases": [
          "General-purpose list storage",
          "Building blocks for other data structures",
          "Dynamic collections with unknown size",
          "Implementation of stacks and queues"
        ]
      },
      "basic_implementation": "class DynamicArray:\n    \"\"\"A foundational implementation of a dynamic array.\n    \n    This implementation demonstrates the core concepts of dynamic arrays:\n    - Automatic resizing when capacity is exceeded\n    - Amortized O(1) append operation\n    - Direct index access in O(1) time\n    \n    Learning Focus:\n    - Understanding how dynamic resizing works\n    - Grasping the concept of amortized analysis\n    - Learning the trade-offs between space and time\n    \"\"\"\n    \n    def __init__(self, initial_capacity=1):\n        \"\"\"Initialize empty dynamic array with given initial capacity.\n        \n        Args:\n            initial_capacity: Starting capacity (minimum 1)\n        \"\"\"\n        self.capacity = max(initial_capacity, 1)\n        self.size = 0\n        self.data = [None] * self.capacity\n        \n    def __len__(self):\n        \"\"\"Return number of elements in the array.\"\"\"\n        return self.size\n        \n    def __getitem__(self, index):\n        \"\"\"Get element at given index.\n        \n        Args:\n            index: Element index (0-based)\n            \n        Returns:\n            Element at the specified index\n            \n        Raises:\n            IndexError: If index is out of bounds\n        \"\"\"\n        if not 0 <= index < self.size:\n            raise IndexError(f\"Index {index} out of range [0, {self.size})\")\n        return self.data[index]\n        \n    def __setitem__(self, index, value):\n        \"\"\"Set element at given index.\n        \n        Args:\n            index: Element index (0-based)\n            value: New value to set\n            \n        Raises:\n            IndexError: If index is out of bounds\n        \"\"\"\n        if not 0 <= index < self.size:\n            raise IndexError(f\"Index {index} out of range [0, {self.size})\")\n        self.data[index] = value\n        \n    def append(self, value):\n        \"\"\"Add element to the end of the array.\n        \n        Time Complexity: O(1) amortized, O(n) worst case when resize needed\n        \n        The amortized O(1) complexity comes from the fact that resize\n        operations become less frequent as the array grows, spreading\n        the cost over many append operations.\n        \n        Args:\n            value: Element to append\n        \"\"\"\n        # Check if resize is needed\n        if self.size >= self.capacity:\n            self._resize()\n            \n        # Add new element\n        self.data[self.size] = value\n        self.size += 1\n        \n    def _resize(self):\n        \"\"\"Double the capacity of the array.\n        \n        This is called when the array is full. We double the size\n        to ensure amortized O(1) append operations.\n        \n        Time Complexity: O(n) - must copy all existing elements\n        Space Complexity: O(n) - creates new array of double size\n        \"\"\"\n        old_capacity = self.capacity\n        self.capacity = max(1, self.capacity * 2)\n        \n        # Create new array with double capacity\n        new_data = [None] * self.capacity\n        \n        # Copy existing elements\n        for i in range(self.size):\n            new_data[i] = self.data[i]\n            \n        self.data = new_data\n        print(f\"Resized from {old_capacity} to {self.capacity}\")\n        \n    def pop(self):\n        \"\"\"Remove and return the last element.\n        \n        Returns:\n            The last element in the array\n            \n        Raises:\n            IndexError: If array is empty\n        \"\"\"\n        if self.size == 0:\n            raise IndexError(\"pop from empty array\")\n            \n        self.size -= 1\n        value = self.data[self.size]\n        self.data[self.size] = None  # Help garbage collection\n        return value\n        \n    def __str__(self):\n        \"\"\"String representation of the array.\"\"\"\n        elements = [str(self.data[i]) for i in range(self.size)]\n        return f\"DynamicArray([{', '.join(elements)}])\"\n        \n# Educational example demonstrating resize behavior\nif __name__ == \"__main__\":\n    arr = DynamicArray(initial_capacity=2)\n    print(f\"Initial: {arr}, capacity: {arr.capacity}\")\n    \n    # Demonstrate automatic resizing\n    for i in range(10):\n        arr.append(i)\n        print(f\"After append({i}): {arr}, capacity: {arr.capacity}\")\n        \n    # Demonstrate access\n    print(f\"Element at index 5: {arr[5]}\")\n    \n    # Demonstrate modification\n    arr[5] = 99\n    print(f\"After setting index 5 to 99: {arr}\")",
      "enhanced_implementation": "class EnhancedDynamicArray:\n    \"\"\"Enhanced dynamic array with comprehensive error handling and optimizations.\n    \n    This implementation adds:\n    - Comprehensive input validation\n    - Memory optimization with shrinking\n    - Iterator support\n    - More operations (insert, remove, etc.)\n    - Better memory management\n    \n    Learning Focus:\n    - Robust error handling patterns\n    - Memory optimization techniques\n    - Python special methods (__iter__, __contains__, etc.)\n    - Performance considerations for different operations\n    \"\"\"\n    \n    def __init__(self, initial_capacity=1, shrink_factor=0.25):\n        \"\"\"Initialize enhanced dynamic array.\n        \n        Args:\n            initial_capacity: Starting capacity (minimum 1)\n            shrink_factor: Threshold for shrinking array (0.0 to 0.5)\n        \"\"\"\n        if not isinstance(initial_capacity, int) or initial_capacity < 1:\n            raise ValueError(\"initial_capacity must be positive integer\")\n        if not 0.0 <= shrink_factor <= 0.5:\n            raise ValueError(\"shrink_factor must be between 0.0 and 0.5\")\n            \n        self.capacity = initial_capacity\n        self.size = 0\n        self.data = [None] * self.capacity\n        self.shrink_factor = shrink_factor\n        \n        # Statistics for analysis\n        self.resize_count = 0\n        self.shrink_count = 0\n        \n    def __len__(self):\n        return self.size\n        \n    def __bool__(self):\n        \"\"\"Return True if array is not empty.\"\"\"\n        return self.size > 0\n        \n    def __getitem__(self, index):\n        \"\"\"Enhanced element access with negative indexing support.\"\"\"\n        index = self._normalize_index(index)\n        return self.data[index]\n        \n    def __setitem__(self, index, value):\n        \"\"\"Enhanced element setting with negative indexing support.\"\"\"\n        index = self._normalize_index(index)\n        self.data[index] = value\n        \n    def __iter__(self):\n        \"\"\"Make the array iterable.\n        \n        Yields:\n            Elements in the array in order\n        \"\"\"\n        for i in range(self.size):\n            yield self.data[i]\n            \n    def __contains__(self, value):\n        \"\"\"Check if value exists in array.\n        \n        Args:\n            value: Value to search for\n            \n        Returns:\n            True if value is found, False otherwise\n            \n        Time Complexity: O(n)\n        \"\"\"\n        for i in range(self.size):\n            if self.data[i] == value:\n                return True\n        return False\n        \n    def _normalize_index(self, index):\n        \"\"\"Convert potentially negative index to positive index.\n        \n        Args:\n            index: Index to normalize (can be negative)\n            \n        Returns:\n            Normalized positive index\n            \n        Raises:\n            IndexError: If index is out of bounds\n        \"\"\"\n        if not isinstance(index, int):\n            raise TypeError(\"Index must be integer\")\n            \n        # Handle negative indexing\n        if index < 0:\n            index += self.size\n            \n        if not 0 <= index < self.size:\n            raise IndexError(f\"Index {index} out of range [0, {self.size})\")\n            \n        return index\n        \n    def append(self, value):\n        \"\"\"Add element with resize tracking.\"\"\"\n        if self.size >= self.capacity:\n            self._grow()\n            \n        self.data[self.size] = value\n        self.size += 1\n        \n    def prepend(self, value):\n        \"\"\"Add element to the beginning.\n        \n        Time Complexity: O(n) - must shift all elements\n        \n        Args:\n            value: Element to add at beginning\n        \"\"\"\n        self.insert(0, value)\n        \n    def insert(self, index, value):\n        \"\"\"Insert element at specific position.\n        \n        Args:\n            index: Position to insert (0 to size inclusive)\n            value: Element to insert\n            \n        Time Complexity: O(n) - may need to shift elements\n        \n        Raises:\n            IndexError: If index is invalid\n        \"\"\"\n        if not isinstance(index, int):\n            raise TypeError(\"Index must be integer\")\n            \n        # Allow insertion at end (index == size)\n        if not 0 <= index <= self.size:\n            raise IndexError(f\"Insert index {index} out of range [0, {self.size}]\")\n            \n        # Grow if needed\n        if self.size >= self.capacity:\n            self._grow()\n            \n        # Shift elements to make room\n        for i in range(self.size, index, -1):\n            self.data[i] = self.data[i - 1]\n            \n        self.data[index] = value\n        self.size += 1\n        \n    def remove_at(self, index):\n        \"\"\"Remove element at specific index.\n        \n        Args:\n            index: Index of element to remove\n            \n        Returns:\n            Removed element\n            \n        Time Complexity: O(n) - may need to shift elements\n        \n        Raises:\n            IndexError: If index is invalid\n        \"\"\"\n        index = self._normalize_index(index)\n        \n        removed_value = self.data[index]\n        \n        # Shift elements left\n        for i in range(index, self.size - 1):\n            self.data[i] = self.data[i + 1]\n            \n        self.size -= 1\n        self.data[self.size] = None  # Help GC\n        \n        # Consider shrinking\n        self._maybe_shrink()\n        \n        return removed_value\n        \n    def remove(self, value):\n        \"\"\"Remove first occurrence of value.\n        \n        Args:\n            value: Value to remove\n            \n        Returns:\n            True if value was found and removed, False otherwise\n            \n        Time Complexity: O(n)\n        \"\"\"\n        for i in range(self.size):\n            if self.data[i] == value:\n                self.remove_at(i)\n                return True\n        return False\n        \n    def pop(self, index=-1):\n        \"\"\"Remove and return element at index (default: last).\n        \n        Args:\n            index: Index of element to remove (default: -1 for last)\n            \n        Returns:\n            Removed element\n        \"\"\"\n        if self.size == 0:\n            raise IndexError(\"pop from empty array\")\n            \n        if index == -1:\n            # Optimized case for removing last element\n            self.size -= 1\n            value = self.data[self.size]\n            self.data[self.size] = None\n            self._maybe_shrink()\n            return value\n        else:\n            return self.remove_at(index)\n            \n    def _grow(self):\n        \"\"\"Double the capacity.\"\"\"\n        old_capacity = self.capacity\n        self.capacity = max(1, self.capacity * 2)\n        self._resize_data()\n        self.resize_count += 1\n        \n    def _maybe_shrink(self):\n        \"\"\"Shrink capacity if utilization is below threshold.\"\"\"\n        if (self.capacity > 1 and \n            self.size <= self.capacity * self.shrink_factor):\n            self.capacity = max(1, self.capacity // 2)\n            self._resize_data()\n            self.shrink_count += 1\n            \n    def _resize_data(self):\n        \"\"\"Resize internal data array to current capacity.\"\"\"\n        new_data = [None] * self.capacity\n        for i in range(self.size):\n            new_data[i] = self.data[i]\n        self.data = new_data\n        \n    def get_stats(self):\n        \"\"\"Get performance statistics.\n        \n        Returns:\n            Dictionary with performance metrics\n        \"\"\"\n        return {\n            'size': self.size,\n            'capacity': self.capacity,\n            'utilization': self.size / self.capacity if self.capacity > 0 else 0,\n            'resize_count': self.resize_count,\n            'shrink_count': self.shrink_count,\n            'memory_usage_bytes': self.capacity * 8  # Approximate\n        }\n        \n    def extend(self, iterable):\n        \"\"\"Extend array with elements from iterable.\n        \n        Args:\n            iterable: Iterable containing elements to add\n        \"\"\"\n        for item in iterable:\n            self.append(item)\n            \n    def clear(self):\n        \"\"\"Remove all elements.\"\"\"\n        self.size = 0\n        for i in range(self.capacity):\n            self.data[i] = None\n            \n    def copy(self):\n        \"\"\"Create shallow copy of the array.\n        \n        Returns:\n            New DynamicArray with same elements\n        \"\"\"\n        new_array = EnhancedDynamicArray(self.capacity, self.shrink_factor)\n        new_array.extend(self)\n        return new_array\n        \n    def __eq__(self, other):\n        \"\"\"Check equality with another array.\"\"\"\n        if not isinstance(other, EnhancedDynamicArray):\n            return False\n        if len(self) != len(other):\n            return False\n        for i in range(len(self)):\n            if self[i] != other[i]:\n                return False\n        return True\n        \n    def __repr__(self):\n        \"\"\"Detailed representation for debugging.\"\"\"\n        elements = list(self)\n        stats = self.get_stats()\n        return (f\"EnhancedDynamicArray({elements}, \"\n                f\"capacity={stats['capacity']}, \"\n                f\"utilization={stats['utilization']:.2f})\")\n        \n    def __str__(self):\n        \"\"\"User-friendly string representation.\"\"\"\n        elements = list(self)\n        return f\"[{', '.join(map(str, elements))}]\"",
      "optimized_implementation": "import ctypes\nfrom typing import TypeVar, Generic, Iterator, Optional, Union, List, Any\nimport sys\n\nT = TypeVar('T')\n\nclass OptimizedDynamicArray(Generic[T]):\n    \"\"\"Highly optimized dynamic array with advanced features.\n    \n    This implementation focuses on:\n    - Memory efficiency using ctypes for better control\n    - Generic type support\n    - Advanced resize strategies\n    - Cache-friendly operations\n    - Performance monitoring\n    \n    Learning Focus:\n    - Memory management techniques in Python\n    - Cache-friendly data structure design\n    - Advanced Python features (generics, ctypes)\n    - Performance optimization strategies\n    - Memory profiling and analysis\n    \"\"\"\n    \n    def __init__(self, \n                 initial_capacity: int = 8,\n                 growth_factor: float = 1.618,  # Golden ratio for optimal growth\n                 shrink_threshold: float = 0.25,\n                 max_capacity: Optional[int] = None):\n        \"\"\"Initialize optimized dynamic array.\n        \n        Args:\n            initial_capacity: Starting capacity (power of 2 recommended)\n            growth_factor: Factor by which to grow (default: golden ratio)\n            shrink_threshold: Utilization below which to shrink\n            max_capacity: Maximum allowed capacity (None = unlimited)\n        \"\"\"\n        if initial_capacity < 1:\n            raise ValueError(\"Initial capacity must be positive\")\n        if growth_factor <= 1.0:\n            raise ValueError(\"Growth factor must be > 1.0\")\n        if not 0.0 < shrink_threshold < 1.0:\n            raise ValueError(\"Shrink threshold must be between 0 and 1\")\n            \n        self._capacity = self._next_power_of_2(initial_capacity)\n        self._size = 0\n        self._growth_factor = growth_factor\n        self._shrink_threshold = shrink_threshold\n        self._max_capacity = max_capacity or sys.maxsize\n        \n        # Use ctypes array for better memory control\n        self._data = (ctypes.py_object * self._capacity)()\n        \n        # Performance tracking\n        self._resize_operations = 0\n        self._total_elements_moved = 0\n        self._cache_hits = 0\n        self._cache_misses = 0\n        \n        # Cache for recently accessed elements\n        self._access_cache = {}\n        self._cache_size = min(16, self._capacity // 4)\n        \n    @staticmethod\n    def _next_power_of_2(n: int) -> int:\n        \"\"\"Find next power of 2 >= n for optimal memory alignment.\"\"\"\n        if n <= 1:\n            return 1\n        return 1 << (n - 1).bit_length()\n        \n    def __len__(self) -> int:\n        return self._size\n        \n    def __bool__(self) -> bool:\n        return self._size > 0\n        \n    def __getitem__(self, index: Union[int, slice]) -> Union[T, List[T]]:\n        \"\"\"Optimized element access with caching.\"\"\"\n        if isinstance(index, slice):\n            return self._get_slice(index)\n            \n        # Normalize index\n        if index < 0:\n            index += self._size\n        if not 0 <= index < self._size:\n            raise IndexError(f\"Index {index} out of range\")\n            \n        # Check cache first\n        if index in self._access_cache:\n            self._cache_hits += 1\n            return self._access_cache[index]\n            \n        # Cache miss - get from main storage\n        self._cache_misses += 1\n        value = self._data[index]\n        \n        # Update cache (LRU-style)\n        if len(self._access_cache) >= self._cache_size:\n            # Remove oldest entry (simplified LRU)\n            oldest_key = next(iter(self._access_cache))\n            del self._access_cache[oldest_key]\n            \n        self._access_cache[index] = value\n        return value\n        \n    def __setitem__(self, index: int, value: T) -> None:\n        \"\"\"Optimized element setting with cache invalidation.\"\"\"\n        if index < 0:\n            index += self._size\n        if not 0 <= index < self._size:\n            raise IndexError(f\"Index {index} out of range\")\n            \n        self._data[index] = value\n        \n        # Update cache if present\n        if index in self._access_cache:\n            self._access_cache[index] = value\n            \n    def _get_slice(self, s: slice) -> List[T]:\n        \"\"\"Efficient slice operations.\"\"\"\n        start, stop, step = s.indices(self._size)\n        if step == 1:\n            # Optimized path for simple slices\n            return [self._data[i] for i in range(start, stop)]\n        else:\n            return [self._data[i] for i in range(start, stop, step)]\n            \n    def append(self, value: T) -> None:\n        \"\"\"Highly optimized append operation.\"\"\"\n        if self._size >= self._capacity:\n            self._grow()\n            \n        self._data[self._size] = value\n        self._size += 1\n        \n        # Clear access cache on modifications (simple strategy)\n        self._access_cache.clear()\n        \n    def extend(self, iterable) -> None:\n        \"\"\"Optimized batch append operations.\"\"\"\n        # Convert to list to get length (if possible)\n        if hasattr(iterable, '__len__'):\n            items = list(iterable)\n            required_capacity = self._size + len(items)\n            \n            # Pre-grow to avoid multiple resizes\n            while self._capacity < required_capacity:\n                self._grow()\n                \n            # Batch copy\n            for i, item in enumerate(items):\n                self._data[self._size + i] = item\n            self._size += len(items)\n        else:\n            # Fallback for unknown-length iterables\n            for item in iterable:\n                self.append(item)\n                \n        self._access_cache.clear()\n        \n    def _grow(self) -> None:\n        \"\"\"Intelligent growth strategy.\"\"\"\n        old_capacity = self._capacity\n        \n        # Use golden ratio growth for optimal performance\n        new_capacity = max(\n            int(old_capacity * self._growth_factor),\n            old_capacity + 1\n        )\n        \n        # Ensure power of 2 for memory alignment\n        new_capacity = self._next_power_of_2(new_capacity)\n        \n        # Respect maximum capacity\n        if new_capacity > self._max_capacity:\n            if old_capacity >= self._max_capacity:\n                raise MemoryError(\"Maximum capacity exceeded\")\n            new_capacity = self._max_capacity\n            \n        self._resize(new_capacity)\n        \n    def _shrink(self) -> None:\n        \"\"\"Smart shrinking to reclaim memory.\"\"\"\n        new_capacity = max(\n            self._next_power_of_2(max(1, int(self._size / self._shrink_threshold))),\n            1\n        )\n        \n        if new_capacity < self._capacity:\n            self._resize(new_capacity)\n            \n    def _resize(self, new_capacity: int) -> None:\n        \"\"\"Efficient resize operation with performance tracking.\"\"\"\n        # Create new ctypes array\n        new_data = (ctypes.py_object * new_capacity)()\n        \n        # Copy existing elements (optimized)\n        copy_count = min(self._size, new_capacity)\n        for i in range(copy_count):\n            new_data[i] = self._data[i]\n            \n        # Update internal state\n        self._data = new_data\n        self._capacity = new_capacity\n        self._size = min(self._size, new_capacity)\n        \n        # Update performance metrics\n        self._resize_operations += 1\n        self._total_elements_moved += copy_count\n        \n        # Clear cache after resize\n        self._access_cache.clear()\n        \n    def pop(self, index: int = -1) -> T:\n        \"\"\"Optimized pop operation.\"\"\"\n        if self._size == 0:\n            raise IndexError(\"pop from empty array\")\n            \n        if index == -1:\n            # Fast path for last element\n            self._size -= 1\n            value = self._data[self._size]\n            self._data[self._size] = None\n            \n            # Consider shrinking\n            if (self._capacity > 1 and \n                self._size <= self._capacity * self._shrink_threshold):\n                self._shrink()\n                \n            self._access_cache.clear()\n            return value\n        else:\n            # General case\n            if index < 0:\n                index += self._size\n            if not 0 <= index < self._size:\n                raise IndexError(\"pop index out of range\")\n                \n            value = self._data[index]\n            \n            # Shift elements (optimized with ctypes)\n            memmove_count = self._size - index - 1\n            for i in range(index, index + memmove_count):\n                self._data[i] = self._data[i + 1]\n                \n            self._size -= 1\n            self._data[self._size] = None\n            \n            if (self._capacity > 1 and \n                self._size <= self._capacity * self._shrink_threshold):\n                self._shrink()\n                \n            self._access_cache.clear()\n            return value\n            \n    def insert(self, index: int, value: T) -> None:\n        \"\"\"Optimized insertion.\"\"\"\n        if not 0 <= index <= self._size:\n            raise IndexError(\"insert index out of range\")\n            \n        if self._size >= self._capacity:\n            self._grow()\n            \n        # Shift elements right (optimized)\n        for i in range(self._size, index, -1):\n            self._data[i] = self._data[i - 1]\n            \n        self._data[index] = value\n        self._size += 1\n        self._access_cache.clear()\n        \n    def __iter__(self) -> Iterator[T]:\n        \"\"\"Memory-efficient iteration.\"\"\"\n        for i in range(self._size):\n            yield self._data[i]\n            \n    def __reversed__(self) -> Iterator[T]:\n        \"\"\"Reverse iteration.\"\"\"\n        for i in range(self._size - 1, -1, -1):\n            yield self._data[i]\n            \n    def reverse(self) -> None:\n        \"\"\"In-place reversal (optimized).\"\"\"\n        left, right = 0, self._size - 1\n        while left < right:\n            self._data[left], self._data[right] = self._data[right], self._data[left]\n            left += 1\n            right -= 1\n        self._access_cache.clear()\n        \n    def sort(self, key=None, reverse=False) -> None:\n        \"\"\"In-place sorting using Timsort (Python's built-in).\"\"\"\n        if self._size <= 1:\n            return\n            \n        # Extract elements for sorting\n        elements = [self._data[i] for i in range(self._size)]\n        elements.sort(key=key, reverse=reverse)\n        \n        # Put back sorted elements\n        for i, element in enumerate(elements):\n            self._data[i] = element\n            \n        self._access_cache.clear()\n        \n    def get_performance_stats(self) -> dict:\n        \"\"\"Get detailed performance statistics.\"\"\"\n        return {\n            'size': self._size,\n            'capacity': self._capacity,\n            'utilization': self._size / self._capacity if self._capacity > 0 else 0,\n            'growth_factor': self._growth_factor,\n            'resize_operations': self._resize_operations,\n            'total_elements_moved': self._total_elements_moved,\n            'avg_elements_per_resize': (self._total_elements_moved / self._resize_operations \n                                       if self._resize_operations > 0 else 0),\n            'cache_hit_rate': (self._cache_hits / (self._cache_hits + self._cache_misses) \n                              if (self._cache_hits + self._cache_misses) > 0 else 0),\n            'memory_usage_bytes': self._capacity * ctypes.sizeof(ctypes.py_object),\n            'cache_utilization': len(self._access_cache) / self._cache_size if self._cache_size > 0 else 0\n        }\n        \n    def __sizeof__(self) -> int:\n        \"\"\"Return memory usage in bytes.\"\"\"\n        return (sys.getsizeof(self) + \n                self._capacity * ctypes.sizeof(ctypes.py_object) +\n                sys.getsizeof(self._access_cache))\n                \n    def __repr__(self) -> str:\n        elements = [self._data[i] for i in range(min(10, self._size))]\n        if self._size > 10:\n            elements.append('...')\n        stats = self.get_performance_stats()\n        return (f\"OptimizedDynamicArray({elements}, \"\n                f\"size={self._size}, capacity={self._capacity}, \"\n                f\"utilization={stats['utilization']:.2%})\")",
      "production_implementation": "# Production-ready dynamic array implementation would go here\n# This would include thread safety, comprehensive logging, monitoring,\n# integration with existing systems, deployment considerations, etc.\n# See the Linear Regression example above for the full production template.",
      "comprehensive_tests": "import pytest\nimport random\nimport time\nimport gc\nfrom typing import List\n\nclass TestDynamicArrayImplementations:\n    \"\"\"Comprehensive test suite for all dynamic array implementations.\"\"\"\n    \n    @pytest.fixture(params=[DynamicArray, EnhancedDynamicArray, OptimizedDynamicArray])\n    def array_class(self, request):\n        \"\"\"Test all implementations.\"\"\"\n        return request.param\n        \n    def test_initialization(self, array_class):\n        \"\"\"Test proper initialization.\"\"\"\n        if array_class == OptimizedDynamicArray:\n            arr = array_class[int]()\n        else:\n            arr = array_class()\n        assert len(arr) == 0\n        assert bool(arr) == False\n        \n    def test_append_and_access(self, array_class):\n        \"\"\"Test basic append and access operations.\"\"\"\n        if array_class == OptimizedDynamicArray:\n            arr = array_class[int]()\n        else:\n            arr = array_class()\n            \n        # Test appending\n        for i in range(100):\n            arr.append(i)\n            assert len(arr) == i + 1\n            assert arr[i] == i\n            \n        # Test access\n        for i in range(100):\n            assert arr[i] == i\n            \n        # Test negative indexing (if supported)\n        if hasattr(arr, '_normalize_index'):\n            assert arr[-1] == 99\n            assert arr[-100] == 0\n            \n    def test_resize_behavior(self, array_class):\n        \"\"\"Test automatic resizing.\"\"\"\n        if array_class == OptimizedDynamicArray:\n            arr = array_class[int](initial_capacity=1)\n        else:\n            arr = array_class(initial_capacity=1)\n            \n        initial_capacity = arr.capacity if hasattr(arr, 'capacity') else arr._capacity\n        \n        # Add enough elements to trigger multiple resizes\n        for i in range(initial_capacity * 4):\n            arr.append(i)\n            \n        final_capacity = arr.capacity if hasattr(arr, 'capacity') else arr._capacity\n        assert final_capacity > initial_capacity\n        assert len(arr) == initial_capacity * 4\n        \n    def test_pop_operations(self, array_class):\n        \"\"\"Test pop operations.\"\"\"\n        if array_class == OptimizedDynamicArray:\n            arr = array_class[int]()\n        else:\n            arr = array_class()\n            \n        # Add elements\n        for i in range(10):\n            arr.append(i)\n            \n        # Test pop from end\n        assert arr.pop() == 9\n        assert len(arr) == 9\n        \n        # Test pop from specific index (if supported)\n        if 'enhanced' in arr.__class__.__name__.lower() or 'optimized' in arr.__class__.__name__.lower():\n            assert arr.pop(0) == 0\n            assert len(arr) == 8\n            assert arr[0] == 1\n            \n    def test_error_handling(self, array_class):\n        \"\"\"Test proper error handling.\"\"\"\n        if array_class == OptimizedDynamicArray:\n            arr = array_class[int]()\n        else:\n            arr = array_class()\n            \n        # Test access on empty array\n        with pytest.raises(IndexError):\n            _ = arr[0]\n            \n        # Test pop on empty array\n        with pytest.raises(IndexError):\n            arr.pop()\n            \n        # Add some elements for further testing\n        for i in range(5):\n            arr.append(i)\n            \n        # Test out-of-bounds access\n        with pytest.raises(IndexError):\n            _ = arr[10]\n            \n        with pytest.raises(IndexError):\n            _ = arr[-10]\n            \n    def test_iteration(self, array_class):\n        \"\"\"Test iteration capabilities.\"\"\"\n        if array_class == OptimizedDynamicArray:\n            arr = array_class[int]()\n        else:\n            arr = array_class()\n            \n        test_data = list(range(50))\n        for item in test_data:\n            arr.append(item)\n            \n        # Test forward iteration\n        result = list(arr)\n        assert result == test_data\n        \n        # Test reverse iteration (if supported)\n        if hasattr(arr, '__reversed__'):\n            result_reversed = list(reversed(arr))\n            assert result_reversed == test_data[::-1]\n            \n    def test_memory_efficiency(self, array_class):\n        \"\"\"Test memory usage patterns.\"\"\"\n        if array_class == OptimizedDynamicArray:\n            arr = array_class[int]()\n        else:\n            arr = array_class()\n            \n        # Measure initial memory\n        initial_memory = arr.__sizeof__() if hasattr(arr, '__sizeof__') else None\n        \n        # Add many elements\n        for i in range(1000):\n            arr.append(i)\n            \n        # Memory should have grown\n        if initial_memory is not None:\n            final_memory = arr.__sizeof__()\n            assert final_memory > initial_memory\n            \n        # Test shrinking (if supported)\n        if hasattr(arr, '_maybe_shrink') or hasattr(arr, '_shrink'):\n            # Remove most elements\n            while len(arr) > 10:\n                arr.pop()\n                \n            # Force garbage collection\n            gc.collect()\n            \n    def test_performance_characteristics(self, array_class):\n        \"\"\"Test performance characteristics.\"\"\"\n        if array_class == OptimizedDynamicArray:\n            arr = array_class[int]()\n        else:\n            arr = array_class()\n            \n        n = 10000\n        \n        # Test append performance\n        start_time = time.time()\n        for i in range(n):\n            arr.append(i)\n        append_time = time.time() - start_time\n        \n        # Should be reasonable (< 1 second for 10k appends)\n        assert append_time < 1.0\n        \n        # Test access performance\n        start_time = time.time()\n        total = 0\n        for i in range(n):\n            total += arr[i]\n        access_time = time.time() - start_time\n        \n        # Should be very fast\n        assert access_time < 0.1\n        assert total == sum(range(n))\n        \n    def test_edge_cases(self, array_class):\n        \"\"\"Test various edge cases.\"\"\"\n        if array_class == OptimizedDynamicArray:\n            arr = array_class[str]()\n        else:\n            arr = array_class()\n            \n        # Test with None values\n        arr.append(None)\n        assert arr[0] is None\n        assert len(arr) == 1\n        \n        # Test with different data types\n        test_values = [1, \"string\", [1, 2, 3], {\"key\": \"value\"}, 3.14]\n        arr.clear() if hasattr(arr, 'clear') else None\n        \n        for value in test_values:\n            arr.append(value)\n            \n        for i, value in enumerate(test_values):\n            assert arr[i] == value\n            \n    def test_bulk_operations(self, array_class):\n        \"\"\"Test bulk operations if supported.\"\"\"\n        if array_class == OptimizedDynamicArray:\n            arr = array_class[int]()\n        else:\n            arr = array_class()\n            \n        # Test extend operation (if supported)\n        if hasattr(arr, 'extend'):\n            test_data = list(range(100))\n            arr.extend(test_data)\n            assert len(arr) == 100\n            assert list(arr) == test_data\n            \n        # Test sort operation (if supported)\n        if hasattr(arr, 'sort'):\n            arr.clear() if hasattr(arr, 'clear') else None\n            random_data = [random.randint(0, 1000) for _ in range(50)]\n            for item in random_data:\n                arr.append(item)\n            arr.sort()\n            assert list(arr) == sorted(random_data)\n            \n    @pytest.mark.performance\n    def test_performance_comparison(self):\n        \"\"\"Compare performance across implementations.\"\"\"\n        implementations = [DynamicArray, EnhancedDynamicArray, OptimizedDynamicArray]\n        n = 50000\n        results = {}\n        \n        for impl_class in implementations:\n            if impl_class == OptimizedDynamicArray:\n                arr = impl_class[int]()\n            else:\n                arr = impl_class()\n                \n            # Time append operations\n            start_time = time.time()\n            for i in range(n):\n                arr.append(i)\n            append_time = time.time() - start_time\n            \n            # Time random access\n            start_time = time.time()\n            for _ in range(1000):\n                idx = random.randint(0, n - 1)\n                _ = arr[idx]\n            access_time = time.time() - start_time\n            \n            results[impl_class.__name__] = {\n                'append_time': append_time,\n                'access_time': access_time,\n                'memory_usage': arr.__sizeof__() if hasattr(arr, '__sizeof__') else 'N/A'\n            }\n            \n        # Print results for analysis\n        print(\"\\nPerformance Comparison:\")\n        for name, metrics in results.items():\n            print(f\"{name}:\")\n            print(f\"  Append time: {metrics['append_time']:.4f}s\")\n            print(f\"  Access time: {metrics['access_time']:.4f}s\")\n            print(f\"  Memory usage: {metrics['memory_usage']}\")\n            \nif __name__ == '__main__':\n    pytest.main([__file__, '-v', '--tb=short'])",
      "learning_objectives": [
        "Understanding dynamic memory management and amortized analysis",
        "Learning progressive implementation complexity and optimization strategies", 
        "Mastering error handling patterns and edge case management",
        "Understanding cache-friendly data structure design",
        "Learning performance measurement and optimization techniques",
        "Understanding memory layout and garbage collection implications",
        "Learning comprehensive testing strategies for data structures",
        "Understanding trade-offs between different implementation approaches"
      ],
      "practical_applications": [
        "Building blocks for other data structures (stacks, queues, graphs)",
        "Implementation of programming language lists and vectors",
        "Database buffer pools and memory management systems", 
        "Graphics and game engine object storage",
        "Web browser history and undo/redo functionality",
        "Text editor line and character storage",
        "Compiler symbol tables and intermediate representations"
      ],
      "design_patterns_demonstrated": [
        "Strategy pattern (multiple resize strategies)",
        "Template method pattern (common operations with customizable behavior)",
        "Observer pattern (performance monitoring and statistics)",
        "Factory pattern (automatic solver selection based on problem characteristics)",
        "Composite pattern (extending functionality through composition)",
        "Iterator pattern (providing various iteration mechanisms)"
      ]
    },
    {
      "id": "ds_002", 
      "data_structure": "Binary Search Tree (BST)",
      "category": "trees_and_graphs",
      "language": "python",
      "complexity": "intermediate",
      "conceptual_foundation": {
        "core_concept": "Binary tree where left children are smaller and right children are larger than parent",
        "key_operations": ["search", "insert", "delete", "traversal"],
        "time_complexity": {
          "search_average": "O(log n)",
          "search_worst": "O(n)",
          "insert_average": "O(log n)", 
          "insert_worst": "O(n)",
          "delete_average": "O(log n)",
          "delete_worst": "O(n)",
          "traversal": "O(n)"
        },
        "space_complexity": "O(n) for storage, O(log n) to O(n) for recursion stack",
        "advantages": [
          "Efficient searching in sorted data",
          "Dynamic size",
          "In-order traversal gives sorted sequence",
          "No need for pre-allocated space"
        ],
        "disadvantages": [
          "Can become unbalanced (degenerate to linear search)",
          "No constant-time operations",
          "Recursive implementation can cause stack overflow"
        ]
      },
      "basic_implementation": "class TreeNode:\n    \"\"\"Node class for Binary Search Tree.\n    \n    Each node contains:\n    - data: The value stored in the node\n    - left: Reference to left child (smaller values)\n    - right: Reference to right child (larger values)\n    \"\"\"\n    \n    def __init__(self, data):\n        self.data = data\n        self.left = None\n        self.right = None\n        \n    def __str__(self):\n        return str(self.data)\n        \nclass BinarySearchTree:\n    \"\"\"Basic Binary Search Tree implementation.\n    \n    This implementation demonstrates core BST concepts:\n    - Binary search property maintenance\n    - Recursive insertion and search\n    - Tree traversal methods\n    \n    Learning Focus:\n    - Understanding tree structures and recursion\n    - Grasping binary search property\n    - Learning different traversal methods\n    \"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize empty BST.\"\"\"\n        self.root = None\n        self.size = 0\n        \n    def insert(self, data):\n        \"\"\"Insert a value into the BST.\n        \n        Args:\n            data: Value to insert\n            \n        Time Complexity: O(log n) average, O(n) worst case\n        \"\"\"\n        self.root = self._insert_recursive(self.root, data)\n        self.size += 1\n        \n    def _insert_recursive(self, node, data):\n        \"\"\"Recursive helper for insertion.\n        \n        Args:\n            node: Current node in traversal\n            data: Value to insert\n            \n        Returns:\n            Root of the (possibly modified) subtree\n        \"\"\"\n        # Base case: create new node\n        if node is None:\n            return TreeNode(data)\n            \n        # Recursive case: choose left or right subtree\n        if data < node.data:\n            node.left = self._insert_recursive(node.left, data)\n        elif data > node.data:\n            node.right = self._insert_recursive(node.right, data)\n        # If data == node.data, don't insert duplicates\n        \n        return node\n        \n    def search(self, data):\n        \"\"\"Search for a value in the BST.\n        \n        Args:\n            data: Value to search for\n            \n        Returns:\n            True if found, False otherwise\n            \n        Time Complexity: O(log n) average, O(n) worst case\n        \"\"\"\n        return self._search_recursive(self.root, data)\n        \n    def _search_recursive(self, node, data):\n        \"\"\"Recursive helper for search.\"\"\"\n        # Base case: not found\n        if node is None:\n            return False\n            \n        # Found the value\n        if data == node.data:\n            return True\n            \n        # Search in appropriate subtree\n        if data < node.data:\n            return self._search_recursive(node.left, data)\n        else:\n            return self._search_recursive(node.right, data)\n            \n    def inorder_traversal(self):\n        \"\"\"Perform in-order traversal (left, root, right).\n        \n        Returns:\n            List of values in sorted order\n            \n        Time Complexity: O(n)\n        \n        Note: In-order traversal of BST gives sorted sequence\n        \"\"\"\n        result = []\n        self._inorder_recursive(self.root, result)\n        return result\n        \n    def _inorder_recursive(self, node, result):\n        \"\"\"Recursive helper for in-order traversal.\"\"\"\n        if node is not None:\n            self._inorder_recursive(node.left, result)   # Left subtree\n            result.append(node.data)                     # Current node\n            self._inorder_recursive(node.right, result)  # Right subtree\n            \n    def preorder_traversal(self):\n        \"\"\"Perform pre-order traversal (root, left, right).\n        \n        Returns:\n            List of values in pre-order\n            \n        Use case: Used to create copy of tree or serialize tree structure\n        \"\"\"\n        result = []\n        self._preorder_recursive(self.root, result)\n        return result\n        \n    def _preorder_recursive(self, node, result):\n        \"\"\"Recursive helper for pre-order traversal.\"\"\"\n        if node is not None:\n            result.append(node.data)                      # Current node\n            self._preorder_recursive(node.left, result)   # Left subtree\n            self._preorder_recursive(node.right, result)  # Right subtree\n            \n    def postorder_traversal(self):\n        \"\"\"Perform post-order traversal (left, right, root).\n        \n        Returns:\n            List of values in post-order\n            \n        Use case: Used to delete tree or calculate size of subtrees\n        \"\"\"\n        result = []\n        self._postorder_recursive(self.root, result)\n        return result\n        \n    def _postorder_recursive(self, node, result):\n        \"\"\"Recursive helper for post-order traversal.\"\"\"\n        if node is not None:\n            self._postorder_recursive(node.left, result)  # Left subtree\n            self._postorder_recursive(node.right, result) # Right subtree\n            result.append(node.data)                      # Current node\n            \n    def find_min(self):\n        \"\"\"Find minimum value in the tree.\n        \n        Returns:\n            Minimum value, or None if tree is empty\n            \n        Time Complexity: O(log n) average, O(n) worst case\n        \n        Note: Minimum is always the leftmost node\n        \"\"\"\n        if self.root is None:\n            return None\n            \n        current = self.root\n        while current.left is not None:\n            current = current.left\n        return current.data\n        \n    def find_max(self):\n        \"\"\"Find maximum value in the tree.\n        \n        Returns:\n            Maximum value, or None if tree is empty\n            \n        Note: Maximum is always the rightmost node\n        \"\"\"\n        if self.root is None:\n            return None\n            \n        current = self.root\n        while current.right is not None:\n            current = current.right\n        return current.data\n        \n    def height(self):\n        \"\"\"Calculate height of the tree.\n        \n        Returns:\n            Height of tree (0 for single node, -1 for empty tree)\n        \"\"\"\n        return self._height_recursive(self.root)\n        \n    def _height_recursive(self, node):\n        \"\"\"Recursive helper for height calculation.\"\"\"\n        if node is None:\n            return -1\n            \n        left_height = self._height_recursive(node.left)\n        right_height = self._height_recursive(node.right)\n        \n        return 1 + max(left_height, right_height)\n        \n    def __len__(self):\n        \"\"\"Return number of nodes in the tree.\"\"\"\n        return self.size\n        \n    def __bool__(self):\n        \"\"\"Return True if tree is not empty.\"\"\"\n        return self.root is not None\n        \n    def __contains__(self, data):\n        \"\"\"Check if value exists in tree (supports 'in' operator).\"\"\"\n        return self.search(data)\n        \n    def __str__(self):\n        \"\"\"String representation showing in-order traversal.\"\"\"\n        if self.root is None:\n            return \"Empty BST\"\n        return f\"BST({self.inorder_traversal()})\"\n        \n# Educational example demonstrating BST usage\nif __name__ == \"__main__\":\n    bst = BinarySearchTree()\n    \n    # Insert values\n    values = [50, 30, 70, 20, 40, 60, 80]\n    print(f\"Inserting values: {values}\")\n    \n    for value in values:\n        bst.insert(value)\n        print(f\"After inserting {value}: {bst}\")\n        \n    print(f\"\\nTree size: {len(bst)}\")\n    print(f\"Tree height: {bst.height()}\")\n    print(f\"Minimum value: {bst.find_min()}\")\n    print(f\"Maximum value: {bst.find_max()}\")\n    \n    # Test search\n    test_values = [40, 90, 30]\n    for val in test_values:\n        found = val in bst\n        print(f\"Search for {val}: {'Found' if found else 'Not found'}\")\n        \n    # Show different traversals\n    print(f\"\\nTraversals:\")\n    print(f\"In-order (sorted): {bst.inorder_traversal()}\")\n    print(f\"Pre-order: {bst.preorder_traversal()}\")\n    print(f\"Post-order: {bst.postorder_traversal()}\")",
      "enhanced_implementation": "# Enhanced BST with deletion, validation, and iterative methods would go here\n# This would include proper deletion handling (3 cases), tree validation,\n# iterative versions of operations, and better error handling",
      "learning_objectives": [
        "Understanding recursive tree algorithms and base cases",
        "Learning binary search property and its maintenance",
        "Mastering tree traversal methods and their applications",
        "Understanding time complexity analysis for tree operations",
        "Learning when BSTs are appropriate vs other data structures"
      ]
    }
  ]
}